/*
Copyright (C) 2018 Christoph Schied
Copyright (C) 2019, NVIDIA CORPORATION. All rights reserved.

This program is free software; you can redistribute it and/or modify
it under the terms of the GNU General Public License as published by
the Free Software Foundation; either version 2 of the License, or
(at your option) any later version.

This program is distributed in the hope that it will be useful,
but WITHOUT ANY WARRANTY; without even the implied warranty of
MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
GNU General Public License for more details.

You should have received a copy of the GNU General Public License along
with this program; if not, write to the Free Software Foundation, Inc.,
51 Franklin Street, Fifth Floor, Boston, MA 02110-1301 USA.
*/

// ========================================================================== //
// A simple temporal anti-aliasing filter that operates in the PQ (Perceptual 
// Quantizer) color space, which improves high-contrast edges - for example, 
// between some geometry and the sun.
// ========================================================================== //

#version 460
#extension GL_GOOGLE_include_directive    : enable
#extension GL_EXT_nonuniform_qualifier    : enable

layout(local_size_x = 16, local_size_y = 16, local_size_z = 1) in;

#define GLOBAL_UBO_DESC_SET_IDX 0
#include "global_ubo.h"

#define GLOBAL_TEXTURES_DESC_SET_IDX 1
#include "global_textures.h"

#include "utils.glsl"
#include "asvgf.glsl"

const float pq_m1 = 0.1593017578125;
const float pq_m2 = 78.84375;
const float pq_c1 = 0.8359375;
const float pq_c2 = 18.8515625;
const float pq_c3 = 18.6875;
const float pq_C = 10000.0;

vec3 PQDecode(vec3 image)
{
    vec3 Np = pow(max(image, 0.0), vec3(1.0 / pq_m2));
    vec3 L = Np - pq_c1;
    L = L / (pq_c2 - pq_c3 * Np);
    L = pow(max(L, 0.0), vec3(1.0 / pq_m1));

    return L * pq_C; // returns cd/m^2
}

vec3 PQEncode(vec3 image)
{
    vec3 L = image / pq_C;
    vec3 Lm = pow(max(L, 0.0), vec3(pq_m1));
    vec3 N = (pq_c1 + pq_c2 * Lm) / (1.0 + pq_c3 * Lm);
    image = pow(N, vec3(pq_m2));

    return clamp(image, vec3(0), vec3(1));
}

void get_moments(ivec2 ipos, int r, out vec3 mom1, out vec3 mom2)
{
    mom1 = vec3(0.0);
    mom2 = vec3(0.0);

    for(int yy = -r; yy <= r; yy++) {
        for(int xx = -r; xx <= r; xx++) {
            if(xx == 0 && yy == 0) 
                continue;

            ivec2 p = ipos + ivec2(xx, yy);
            vec3 c = texelFetch(TEX_FLAT_COLOR, p, 0).rgb;
            c = PQEncode(c);

            mom1 += c.rgb;
            mom2 += c.rgb * c.rgb;
        }
    }
}

void
main()
{
	ivec2 ipos = ivec2(gl_GlobalInvocationID);

    vec4 linear_color_center = texelFetch(TEX_FLAT_COLOR, ipos, 0);
    vec3 color_center = PQEncode(linear_color_center.rgb);
    
    vec3 color_output = color_center;
    vec3 linear_color_output = linear_color_center.rgb;

    if(global_ubo.flt_taa != 0)
    {
        // Regular TAA mode

        vec3 mom1;
        vec3 mom2;

        int num_pix;

        // Obtain the color moments for the surrounding pixels.
        if(linear_color_center.a > 0)
        {
            // If this is a checkerboarded material (glass, water), use a 5x5 window for moments
            get_moments(ipos, 2, mom1, mom2);
            num_pix = 25;
        }
        else
        {
            // For regular materials, 3x3 pixels is enough
            get_moments(ipos, 1, mom1, mom2);
            num_pix = 9;
        }

        // Remove or reduce sparkles by clamping the color of the center pixel to its surroundings
        if(global_ubo.flt_taa_anti_sparkle > 0)
        {
            // Custom curve to make perceived blurriness depend on the cvar in a roughly linear way
            float scale = pow(min(1.0, global_ubo.flt_taa_anti_sparkle), -0.25);

            color_center = min(color_center, scale * mom1 / (num_pix - 1));
        }

        mom1 += color_center;
        mom2 += color_center * color_center;

        mom1 /= float(num_pix);
        mom2 /= float(num_pix);

        // Find the longest motion vector in a 3x3 window
        vec2 motion;
        {
            float len = -1;
            const int r = 1;
            for(int yy = -r; yy <= r; yy++) {
                for(int xx = -r; xx <= r; xx++) {
                    ivec2 p = ipos + ivec2(xx, yy);
                    vec2 m = texelFetch(TEX_FLAT_MOTION, p, 0).xy;
                    float l = dot(m, m);
                    if(l > len) {
                        len = l;
                        motion = m;
                    }

                }
            }
        }
        
        motion *= vec2(global_ubo.width, global_ubo.height);
        vec2 pos_prev = vec2(ipos) + vec2(0.5) + motion.xy;

        if(all(greaterThanEqual(ivec2(pos_prev), ivec2(1)))
        && all(lessThan(ivec2(pos_prev), ivec2(global_ubo.width, global_ubo.height) - 1))) 
        {
            // Motion vector was valid - sample the previous frame
            vec3 color_prev = sample_texture_catmull_rom(TEX_ASVGF_TAA_B, pos_prev).rgb;

            // If enabled, apply neighbourhood color clamping (NCC)
            if(global_ubo.flt_taa_variance > 0)
            {
                vec3 sigma = sqrt(max(vec3(0), mom2 - mom1 * mom1));
                vec3 mi = mom1 - sigma * global_ubo.flt_taa_variance;
                vec3 ma = mom1 + sigma * global_ubo.flt_taa_variance;

                if(any(isnan(color_prev)))
                    color_prev = vec3(0);

                color_prev = clamp(color_prev, mi, ma);
            }

            // Mix the new color with the clamped previous color
            color_output = mix(color_center, color_prev, clamp(global_ubo.flt_taa_history_weight, 0, 0.999));
        }

        linear_color_output = PQDecode(color_output);
    }
    else if(global_ubo.temporal_blend_factor > 0)
    {
        // Temporal accumulation in reference path tracing mode.
        // The frame is supposed to be static (paused), so no motion vectors or high quality sampling.
        // The accumulator is an RGBA32_FLOAT texture for higher accuracy.

        if(global_ubo.temporal_blend_factor < 1)
        {
            vec3 prev_color = imageLoad(IMG_HQ_COLOR_INTERLEAVED, ipos).rgb;
            linear_color_output = mix(prev_color, linear_color_output, global_ubo.temporal_blend_factor);
        }
        
        imageStore(IMG_HQ_COLOR_INTERLEAVED, ipos, vec4(linear_color_output, 0));

        color_output = PQEncode(linear_color_output);
    }

    imageStore(IMG_ASVGF_TAA_A, ipos, vec4(color_output, 0));
	imageStore(IMG_TAA_OUTPUT, ipos, vec4(linear_color_output, 1));
}
